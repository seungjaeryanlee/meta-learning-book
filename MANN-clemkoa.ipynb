{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62e673f9-11e0-45b2-bb6f-62504ca42524",
   "metadata": {},
   "source": [
    "# `clemkoa/ntm`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a4dd7-d7c0-4ceb-ab0c-5dc8917e7324",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7718cf2d-c4e7-45d9-8c22-f4f1cc902027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def roll(t, n):\n",
    "    temp = t.flip(1)\n",
    "    return torch.cat((temp[:, -(n+1):], temp[:, :-(n+1)]), dim=1)\n",
    "\n",
    "\n",
    "def circular_convolution(w, s):\n",
    "    temp_cat = torch.t(torch.cat([roll(s, i) for i in range(w.shape[1])]))\n",
    "    return torch.mm(w, temp_cat)\n",
    "\n",
    "\n",
    "def _convolve(w, s):\n",
    "    \"\"\"Circular convolution implementation.\"\"\"\n",
    "    assert s.size(0) == 3\n",
    "    t = torch.cat([w[-1:], w, w[:1]], dim=0)\n",
    "    c = F.conv1d(t.view(1, 1, -1), s.view(1, 1, -1)).view(-1)\n",
    "    return c\n",
    "\n",
    "\n",
    "def plot_copy_results(target, y, vector_length):\n",
    "    plt.set_cmap('jet')\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    ax1.set_ylabel(\"target\", rotation=0, labelpad=20)\n",
    "    ax1.imshow(torch.t(target.view(-1, vector_length)))\n",
    "    ax1.tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "    ax2 = fig.add_subplot(212)\n",
    "    ax2.set_ylabel(\"output\", rotation=0, labelpad=20)\n",
    "    ax2.imshow(torch.t(y.clone().data.view(-1, vector_length)))\n",
    "    ax2.tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "    plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "    plt.setp(ax1.get_yticklabels(), visible=False)\n",
    "    plt.setp(ax2.get_xticklabels(), visible=False)\n",
    "    plt.setp(ax2.get_yticklabels(), visible=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d213ddf4-eaef-4013-b1f0-3826633ee61e",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## `memory.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0db1337-693e-4b4f-8649-5b49ad82087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Parameter\n",
    "\n",
    "\n",
    "class Memory(nn.Module):\n",
    "    def __init__(self, memory_size):\n",
    "        super(Memory, self).__init__()\n",
    "        self._memory_size = memory_size\n",
    "\n",
    "        # Initialize memory bias\n",
    "        initial_state = torch.ones(memory_size) * 1e-6\n",
    "        self.register_buffer('initial_state', initial_state.data)\n",
    "\n",
    "        # Initial read vector is a learnt parameter\n",
    "        self.initial_read = Parameter(torch.randn(1, self._memory_size[1]) * 0.01)\n",
    "\n",
    "    def get_size(self):\n",
    "        return self._memory_size\n",
    "\n",
    "    def reset(self, batch_size):\n",
    "        self.memory = self.initial_state.clone().repeat(batch_size, 1, 1)\n",
    "\n",
    "    def get_initial_read(self, batch_size):\n",
    "        return self.initial_read.clone().repeat(batch_size, 1)\n",
    "\n",
    "    def read(self):\n",
    "        return self.memory\n",
    "\n",
    "    def write(self, w, e, a):\n",
    "        self.memory = self.memory * (1 - torch.matmul(w.unsqueeze(-1), e.unsqueeze(1)))\n",
    "        self.memory = self.memory + torch.matmul(w.unsqueeze(-1), a.unsqueeze(1))\n",
    "        return self.memory\n",
    "\n",
    "    def size(self):\n",
    "        return self._memory_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b0aa9f-aace-4f6a-9733-b903556bdbc3",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## `head.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f2192c-cd73-4437-af95-f67b7c4c4c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "# from ntm.utils import _convolve\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, memory, hidden_size):\n",
    "        super(Head, self).__init__()\n",
    "        self.memory = memory\n",
    "        memory_length, memory_vector_length = memory.get_size()\n",
    "        # (k : vector, beta: scalar, g: scalar, s: vector, gamma: scalar)\n",
    "        self.k_layer = nn.Linear(hidden_size, memory_vector_length)\n",
    "        self.beta_layer = nn.Linear(hidden_size, 1)\n",
    "        self.g_layer = nn.Linear(hidden_size, 1)\n",
    "        self.s_layer = nn.Linear(hidden_size, 3)\n",
    "        self.gamma_layer = nn.Linear(hidden_size, 1)\n",
    "        for layer in [self.k_layer, self.beta_layer, self.g_layer, self.s_layer, self.gamma_layer]:\n",
    "            nn.init.xavier_uniform_(layer.weight, gain=1.4)\n",
    "            nn.init.normal_(layer.bias, std=0.01)\n",
    "\n",
    "        self._initial_state = Parameter(torch.randn(1, self.memory.get_size()[0]) * 1e-5)\n",
    "\n",
    "    def get_initial_state(self, batch_size):\n",
    "        # Softmax to ensure weights are normalized\n",
    "        return F.softmax(self._initial_state, dim=1).repeat(batch_size, 1)\n",
    "\n",
    "    def get_head_weight(self, x, previous_state, memory_read):\n",
    "        k = self.k_layer(x)\n",
    "        beta = F.softplus(self.beta_layer(x))\n",
    "        g = F.sigmoid(self.g_layer(x))\n",
    "        s = F.softmax(self.s_layer(x), dim=1)\n",
    "        gamma = 1 + F.softplus(self.gamma_layer(x))\n",
    "        # Focusing by content\n",
    "        w_c = F.softmax(beta * F.cosine_similarity(memory_read + 1e-16, k.unsqueeze(1) + 1e-16, dim=-1), dim=1)\n",
    "        # Focusing by location\n",
    "        w_g = g * w_c + (1 - g) * previous_state\n",
    "        w_t = self.shift(w_g, s)\n",
    "        w = w_t ** gamma\n",
    "        w = torch.div(w, torch.sum(w, dim=1).unsqueeze(1) + 1e-16)\n",
    "        return w\n",
    "\n",
    "    def shift(self, w_g, s):\n",
    "        result = w_g.clone()\n",
    "        for b in range(len(w_g)):\n",
    "            result[b] = _convolve(w_g[b], s[b])\n",
    "        return result\n",
    "\n",
    "\n",
    "class ReadHead(Head):\n",
    "    def forward(self, x, previous_state):\n",
    "        memory_read = self.memory.read()\n",
    "        w = self.get_head_weight(x, previous_state, memory_read)\n",
    "        return torch.matmul(w.unsqueeze(1), memory_read).squeeze(1), w\n",
    "\n",
    "\n",
    "class WriteHead(Head):\n",
    "    def __init__(self, memory, hidden_size):\n",
    "        super(WriteHead, self).__init__(memory, hidden_size)\n",
    "        memory_length, memory_vector_length = memory.get_size()\n",
    "        self.e_layer = nn.Linear(hidden_size, memory_vector_length)\n",
    "        self.a_layer = nn.Linear(hidden_size, memory_vector_length)\n",
    "        for layer in [self.e_layer, self.a_layer]:\n",
    "            nn.init.xavier_uniform_(layer.weight, gain=1.4)\n",
    "            nn.init.normal_(layer.bias, std=0.01)\n",
    "\n",
    "    def forward(self, x, previous_state):\n",
    "        memory_read = self.memory.read()\n",
    "        w = self.get_head_weight(x, previous_state, memory_read)\n",
    "        e = F.sigmoid(self.e_layer(x))\n",
    "        a = self.a_layer(x)\n",
    "\n",
    "        # write to memory (w, memory, e , a)\n",
    "        self.memory.write(w, e, a)\n",
    "        return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1f7af3-7312-4543-aa41-c5a36a2e2075",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## `controller.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1edc450-259b-4178-8903-d339ddc147f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Parameter\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Controller(nn.Module):\n",
    "    def __init__(self, lstm_controller, vector_length, hidden_size):\n",
    "        super(Controller, self).__init__()\n",
    "        # We allow either a feed-forward network or a LSTM for the controller\n",
    "        self._lstm_controller = lstm_controller\n",
    "        if self._lstm_controller:\n",
    "            self._controller = LSTMController(vector_length, hidden_size)\n",
    "        else:\n",
    "            self._controller = FeedForwardController(vector_length, hidden_size)\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        return self._controller(x, state)\n",
    "\n",
    "    def get_initial_state(self, batch_size):\n",
    "        return self._controller.get_initial_state(batch_size)\n",
    "\n",
    "\n",
    "class LSTMController(nn.Module):\n",
    "    def __init__(self, vector_length, hidden_size):\n",
    "        super(LSTMController, self).__init__()\n",
    "        self.layer = nn.LSTM(input_size=vector_length, hidden_size=hidden_size)\n",
    "        # The hidden state is a learned parameter\n",
    "        self.lstm_h_state = Parameter(torch.randn(1, 1, hidden_size) * 0.05)\n",
    "        self.lstm_c_state = Parameter(torch.randn(1, 1, hidden_size) * 0.05)\n",
    "        for p in self.layer.parameters():\n",
    "            if p.dim() == 1:\n",
    "                nn.init.constant_(p, 0)\n",
    "            else:\n",
    "                stdev = 5 / (np.sqrt(vector_length + hidden_size))\n",
    "                nn.init.uniform_(p, -stdev, stdev)\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        output, state = self.layer(x.unsqueeze(0), state)\n",
    "        return output.squeeze(0), state\n",
    "\n",
    "    def get_initial_state(self, batch_size):\n",
    "        lstm_h = self.lstm_h_state.clone().repeat(1, batch_size, 1)\n",
    "        lstm_c = self.lstm_c_state.clone().repeat(1, batch_size, 1)\n",
    "        return lstm_h, lstm_c\n",
    "\n",
    "\n",
    "class FeedForwardController(nn.Module):\n",
    "    def __init__(self, vector_length, hidden_size):\n",
    "        super(FeedForwardController, self).__init__()\n",
    "        self.layer_1 = nn.Linear(vector_length, hidden_size)\n",
    "        self.layer_2 = nn.Linear(hidden_size, hidden_size)\n",
    "        stdev = 5 / (np.sqrt(vector_length + hidden_size))\n",
    "        nn.init.uniform_(self.layer_1.weight, -stdev, stdev)\n",
    "        nn.init.uniform_(self.layer_2.weight, -stdev, stdev)\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        x1 = F.relu(self.layer_1(x))\n",
    "        output = F.relu(self.layer_2(x1))\n",
    "        return output, state\n",
    "\n",
    "    def get_initial_state(self):\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b95768-a1ba-4844-af66-77c2d2b5b3fd",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## `ntm.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a63ff5c2-63fb-405e-bcc1-3f83b4458f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "# from ntm.controller import Controller\n",
    "# from ntm.memory import Memory\n",
    "# from ntm.head import ReadHead, WriteHead\n",
    "\n",
    "\n",
    "class NTM(nn.Module):\n",
    "    def __init__(self, vector_length, hidden_size, memory_size, lstm_controller=True):\n",
    "        super(NTM, self).__init__()\n",
    "        self.controller = Controller(lstm_controller, vector_length + 1 + memory_size[1], hidden_size)\n",
    "        self.memory = Memory(memory_size)\n",
    "        self.read_head = ReadHead(self.memory, hidden_size)\n",
    "        self.write_head = WriteHead(self.memory, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size + memory_size[1], 5)\n",
    "        nn.init.xavier_uniform_(self.fc.weight, gain=1)\n",
    "        nn.init.normal_(self.fc.bias, std=0.01)\n",
    "\n",
    "    def get_initial_state(self, batch_size=1):\n",
    "        self.memory.reset(batch_size)\n",
    "        controller_state = self.controller.get_initial_state(batch_size)\n",
    "        read = self.memory.get_initial_read(batch_size)\n",
    "        read_head_state = self.read_head.get_initial_state(batch_size)\n",
    "        write_head_state = self.write_head.get_initial_state(batch_size)\n",
    "        return (read, read_head_state, write_head_state, controller_state)\n",
    "\n",
    "    def forward(self, x, previous_state):\n",
    "        previous_read, previous_read_head_state, previous_write_head_state, previous_controller_state = previous_state\n",
    "        controller_input = torch.cat([x, previous_read], dim=1)\n",
    "        controller_output, controller_state = self.controller(controller_input, previous_controller_state)\n",
    "        # Read\n",
    "        read_head_output, read_head_state = self.read_head(controller_output, previous_read_head_state)\n",
    "        # Write\n",
    "        write_head_state = self.write_head(controller_output, previous_write_head_state)\n",
    "        fc_input = torch.cat((controller_output, read_head_output), dim=1)\n",
    "        state = (read_head_output, read_head_state, write_head_state, controller_state)\n",
    "        return F.softmax(self.fc(fc_input)), state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400127f0-d299-41e4-80d0-e193ad211981",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## `repeat_task.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e680bbd-608b-4045-8b46-4a481dd8884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "# from ntm.ntm import NTM\n",
    "# from ntm.utils import plot_copy_results\n",
    "import argparse\n",
    "import numpy as np\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9d3b3ad-c4a6-45c7-9525-3e18527c57d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description=\"Process some integers.\")\n",
    "# parser.add_argument(\"--train\", help=\"Trains the model\", action=\"store_true\")\n",
    "# parser.add_argument(\"--ff\", help=\"Feed forward controller\", action=\"store_true\")\n",
    "# parser.add_argument(\"--eval\", help=\"Evaluates the model. Default path is models/repeat.pt\", action=\"store_true\")\n",
    "# parser.add_argument(\"--modelpath\", help=\"Specify the model path to load, for training or evaluation\", type=str)\n",
    "# parser.add_argument(\"--epochs\", help=\"Specify the number of epochs for training\", type=int, default=50_000)\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03a1f792-c12f-40b1-a85d-504ba41c9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "args = SimpleNamespace()\n",
    "args.train = True\n",
    "args.ff = False\n",
    "args.eval = False\n",
    "args.modelpath = \"models/repeat.pt\"\n",
    "args.epochs = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b44b091-570c-40b1-ac17-dd3a4bb4e96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5e98086f50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85eafcfa-ef73-4335-9028-59436310ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_sequence(sequence_min_length, sequence_max_length, repeat_min, repeat_max, vector_length, batch_size=1):\n",
    "    sequence_length = random.randint(sequence_min_length, sequence_max_length)\n",
    "    repeat = random.randint(repeat_min, repeat_max)\n",
    "\n",
    "    target = torch.bernoulli(torch.Tensor(sequence_length, batch_size, vector_length).uniform_(0, 1))\n",
    "\n",
    "    input = torch.zeros(sequence_length + 2, batch_size, vector_length + 2)\n",
    "    input[:sequence_length, :, :vector_length] = target\n",
    "    # delimiter vector\n",
    "    input[sequence_length, :, vector_length] = 1.0\n",
    "    # repeat channel\n",
    "    input[sequence_length + 1, :, vector_length + 1] = repeat / sequence_max_length\n",
    "\n",
    "    output = torch.zeros(sequence_length * repeat + 1, batch_size, vector_length + 1)\n",
    "    output[:sequence_length * repeat, :, :vector_length] = target.clone().repeat(repeat, 1, 1)\n",
    "    # delimiter vector\n",
    "    output[-1, :, -1] = 1.0\n",
    "    return input, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a28c788c-ad9b-4d14-a187-331f7a0631f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=50_000):\n",
    "#     tensorboard_log_folder = f\"runs/repeat-copy-task-{datetime.now().strftime('%Y-%m-%dT%H%M%S')}\"\n",
    "#     writer = SummaryWriter(tensorboard_log_folder)\n",
    "#     print(f\"Training for {epochs} epochs, logging in {tensorboard_log_folder}\")\n",
    "    sequence_min_length = 1\n",
    "    sequence_max_length = 10\n",
    "    repeat_min = 1\n",
    "    repeat_max = 10\n",
    "    vector_length = 8\n",
    "    memory_size = (128, 20)\n",
    "    hidden_layer_size = 100\n",
    "    batch_size = 4\n",
    "    lstm_controller = not args.ff\n",
    "\n",
    "#     writer.add_scalar(\"sequence_min_length\", sequence_min_length)\n",
    "#     writer.add_scalar(\"sequence_max_length\", sequence_max_length)\n",
    "#     writer.add_scalar(\"vector_length\", vector_length)\n",
    "#     writer.add_scalar(\"memory_size0\", memory_size[0])\n",
    "#     writer.add_scalar(\"memory_size1\", memory_size[1])\n",
    "#     writer.add_scalar(\"hidden_layer_size\", hidden_layer_size)\n",
    "#     writer.add_scalar(\"lstm_controller\", lstm_controller)\n",
    "#     writer.add_scalar(\"seed\", seed)\n",
    "#     writer.add_scalar(\"batch_size\", batch_size)\n",
    "\n",
    "    model = NTM(vector_length + 1, hidden_layer_size, memory_size, lstm_controller)\n",
    "\n",
    "    optimizer = optim.RMSprop(model.parameters(), momentum=0.9, alpha=0.95, lr=1e-4)\n",
    "    feedback_frequency = 100\n",
    "    total_loss = []\n",
    "    total_cost = []\n",
    "\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    if os.path.isfile(model_path):\n",
    "        print(f\"Loading model from {model_path}\")\n",
    "        checkpoint = torch.load(model_path)\n",
    "        model.load_state_dict(checkpoint)\n",
    "\n",
    "    for epoch in range(epochs + 1):\n",
    "        optimizer.zero_grad()\n",
    "        input, target = get_training_sequence(sequence_min_length, sequence_max_length, repeat_min, repeat_max, vector_length, batch_size)\n",
    "        state = model.get_initial_state(batch_size)\n",
    "        for vector in input:\n",
    "            _, state = model(vector, state)\n",
    "        y_out = torch.zeros(target.size())\n",
    "        for j in range(len(target)):\n",
    "            y_out[j], state = model(torch.zeros(batch_size, vector_length + 2), state)\n",
    "        loss = F.binary_cross_entropy(y_out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss.append(loss.item())\n",
    "        y_out_binarized = y_out.clone().data\n",
    "        y_out_binarized.apply_(lambda x: 0 if x < 0.5 else 1)\n",
    "        cost = torch.sum(torch.abs(y_out_binarized - target)) / len(target)\n",
    "        total_cost.append(cost.item())\n",
    "        if epoch % feedback_frequency == 0:\n",
    "            running_loss = sum(total_loss) / len(total_loss)\n",
    "            running_cost = sum(total_cost) / len(total_cost)\n",
    "            print(f\"Loss at step {epoch}: {running_loss}\")\n",
    "#             writer.add_scalar('training loss', running_loss, epoch)\n",
    "#             writer.add_scalar('training cost', running_cost, epoch)\n",
    "            total_loss = []\n",
    "            total_cost = []\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f93fe6b-84fd-495d-a630-ea8ce0b05188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model_path):\n",
    "    vector_length = 8\n",
    "    memory_size = (128, 20)\n",
    "    hidden_layer_size = 100\n",
    "    lstm_controller = not args.ff\n",
    "\n",
    "    model = NTM(vector_length + 1, hidden_layer_size, memory_size, lstm_controller)\n",
    "\n",
    "    print(f\"Loading model from {model_path}\")\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    input, target = get_training_sequence(10, 10, 10, 10, vector_length)\n",
    "    y_out = infer_sequence(model, input, target, vector_length)\n",
    "    plot_copy_results(target, y_out, vector_length + 1)\n",
    "\n",
    "    input, target = get_training_sequence(10, 10, 20, 20, vector_length)\n",
    "    y_out = infer_sequence(model, input, target, vector_length)\n",
    "    plot_copy_results(target, y_out, vector_length + 1)\n",
    "\n",
    "    input, target = get_training_sequence(20, 20, 10, 10, vector_length)\n",
    "    y_out = infer_sequence(model, input, target, vector_length)\n",
    "    plot_copy_results(target, y_out, vector_length + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b87c13ee-1187-418e-a64d-ba7342fd2527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_sequence(model, input, target, vector_length):\n",
    "    state = model.get_initial_state()\n",
    "    for vector in input:\n",
    "        _, state = model(vector, state)\n",
    "    y_out = torch.zeros(target.size())\n",
    "    for j in range(len(target)):\n",
    "        y_out[j], state = model(torch.zeros(1, vector_length + 2), state)\n",
    "    return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81ee57b3-933a-4b1f-b184-4fe169ec6cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     model_path = \"models/repeat.pt\"\n",
    "#     if args.modelpath:\n",
    "#         model_path = args.modelpath\n",
    "#     if args.train:\n",
    "#         train(args.epochs)\n",
    "#     if args.eval:\n",
    "#         eval(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd26afb-7d8f-4bd9-bc03-dc9d577ebb87",
   "metadata": {},
   "source": [
    "# My Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6c566-0a0b-4de0-a224-c5ed62ff3c93",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Omniglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c30a101c-39b5-4dbe-a500-81242660facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmeta.datasets import Omniglot\n",
    "from torchmeta.transforms import Categorical, ClassSplitter, Rotation\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torchmeta.utils.data import BatchMetaDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00894455-5ffa-41ea-9ba1-0d983977a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Omniglot(\n",
    "    \"data\",\n",
    "    # Number of ways\n",
    "    num_classes_per_task=5,\n",
    "    # Resize the images to 20x20 and converts them to PyTorch tensors (from Torchvision)\n",
    "    transform=Compose([Resize(20), ToTensor()]),\n",
    "    # Transform the labels to integers (e.g. (\"Glagolitic/character01\", \"Sanskrit/character14\", ...) to (0, 1, ...))\n",
    "    target_transform=Categorical(num_classes=5),\n",
    "    # Creates new virtual classes with rotated versions of the images (from Santoro et al., 2016)\n",
    "    class_augmentations=[Rotation([90, 180, 270])],\n",
    "    meta_train=True,\n",
    "    download=True,\n",
    ")\n",
    "dataset = ClassSplitter(dataset, shuffle=True, num_train_per_class=5, num_test_per_class=5)\n",
    "dataloader = BatchMetaDataLoader(dataset, batch_size=16, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61ab82b7-7bb9-4b9e-a647-aebed4655e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs_targets_to_seq(inputs, targets):\n",
    "    X = inputs.flatten(2, 4)\n",
    "    y = F.one_hot(targets, num_classes=5)\n",
    "    y = torch.cat((torch.zeros(y.shape[0], 1, y.shape[2]), y), dim=1)[:, :-1, :]\n",
    "    seq = torch.cat((X, y), dim=2)\n",
    "    seq = torch.swapaxes(seq, 0, 1)\n",
    "\n",
    "    # Shape: (seq_len, batch, n_features)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "711c4e7c-3467-443c-826d-7a23d70fd8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seungjaeryanlee/anaconda3/envs/meta-learning-book/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/seungjaeryanlee/anaconda3/envs/meta-learning-book/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/seungjaeryanlee/anaconda3/envs/meta-learning-book/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/seungjaeryanlee/anaconda3/envs/meta-learning-book/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 16, 405])\n"
     ]
    }
   ],
   "source": [
    "for episode_i, batch in enumerate(dataloader):\n",
    "    train_inputs, train_targets = batch[\"train\"]\n",
    "    seq = inputs_targets_to_seq(train_inputs, train_targets)\n",
    "    print(seq.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6ea74e-20bd-4c28-9084-a18d15d0a409",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb90f9e4-0ed1-4e3f-a9c6-45a93e136c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_length = 404\n",
    "hidden_layer_size = 200\n",
    "memory_size = (128, 40)\n",
    "lstm_controller = True\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d888660-cf17-4671-a3be-5d14b0f08c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NTM(vector_length, hidden_layer_size, memory_size, lstm_controller)\n",
    "optimizer = optim.RMSprop(model.parameters(), momentum=0.9, alpha=0.95, lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96d0bff-33b7-4ec8-a65c-6cb676cf6329",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b3fc045-e4ad-4fc8-91e6-bf2b5971a8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seungjaeryanlee/anaconda3/envs/meta-learning-book/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/seungjaeryanlee/anaconda3/envs/meta-learning-book/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/seungjaeryanlee/anaconda3/envs/meta-learning-book/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/seungjaeryanlee/anaconda3/envs/meta-learning-book/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/seungjaeryanlee/anaconda3/envs/meta-learning-book/lib/python3.9/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/tmp/ipykernel_1403/1413676678.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(self.fc(fc_input)), state\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 1.6131 0.1575\n",
      "   10 1.5816 0.4250\n",
      "   20 1.5070 0.5200\n",
      "   30 1.4840 0.4850\n",
      "   40 1.4069 0.6025\n",
      "   50 1.3434 0.6800\n",
      "   60 1.2976 0.7375\n",
      "   70 1.2532 0.7575\n",
      "   80 1.2153 0.7800\n",
      "   90 1.2049 0.7750\n",
      "  100 1.1748 0.8000\n",
      "  110 1.1569 0.7975\n",
      "  120 1.1408 0.8100\n",
      "  130 1.1230 0.8225\n",
      "  140 1.1144 0.8450\n",
      "  150 1.1042 0.8300\n",
      "  160 1.0916 0.8300\n",
      "  170 1.0753 0.8650\n",
      "  180 1.0733 0.8525\n",
      "  190 1.0856 0.8275\n",
      "  200 1.0537 0.8775\n",
      "  210 1.0538 0.8700\n",
      "  220 1.0506 0.8700\n",
      "  230 1.0466 0.8625\n",
      "  240 1.0550 0.8625\n",
      "  250 1.0349 0.8950\n",
      "  260 1.0332 0.8800\n",
      "  270 1.0310 0.8750\n",
      "  280 1.0210 0.8975\n",
      "  290 1.0254 0.8800\n",
      "  300 1.0223 0.8850\n",
      "  310 1.0220 0.8900\n",
      "  320 1.0121 0.8975\n",
      "  330 1.0181 0.8925\n",
      "  340 1.0147 0.8925\n",
      "  350 1.0180 0.9000\n",
      "  360 1.0124 0.8925\n",
      "  370 1.0269 0.8650\n",
      "  380 1.0139 0.8825\n",
      "  390 1.0155 0.8900\n",
      "  400 1.0093 0.9100\n",
      "  410 1.0160 0.8725\n",
      "  420 1.0131 0.8925\n",
      "  430 1.0087 0.8950\n",
      "  440 1.0022 0.9075\n",
      "  450 1.0039 0.8950\n",
      "  460 1.0098 0.8900\n",
      "  470 1.0148 0.8800\n",
      "  480 1.0075 0.8975\n",
      "  490 1.0130 0.8800\n",
      "  500 1.0106 0.8850\n",
      "  510 1.0093 0.8875\n",
      "  520 1.0147 0.8900\n",
      "  530 1.0044 0.8900\n",
      "  540 1.0137 0.8775\n",
      "  550 1.0061 0.9075\n",
      "  560 1.0164 0.8775\n",
      "  570 1.0066 0.9050\n",
      "  580 1.0090 0.8975\n",
      "  590 1.0117 0.8775\n",
      "  600 1.0036 0.8925\n",
      "  610 1.0073 0.8850\n",
      "  620 1.0135 0.8750\n",
      "  630 1.0078 0.8975\n",
      "  640 1.0171 0.8800\n",
      "  650 0.9999 0.9000\n",
      "  660 1.0116 0.8825\n",
      "  670 1.0114 0.8925\n",
      "  680 1.0079 0.8875\n",
      "  690 1.0080 0.8700\n",
      "  700 1.0186 0.8825\n",
      "  710 0.9976 0.9075\n",
      "  720 1.0146 0.8800\n",
      "  730 1.0017 0.9075\n",
      "  740 1.0093 0.8925\n",
      "  750 1.0054 0.8950\n",
      "  760 1.0074 0.8900\n",
      "  770 1.0052 0.8850\n",
      "  780 1.0092 0.8925\n",
      "  790 1.0008 0.8900\n",
      "  800 1.0081 0.8900\n",
      "  810 1.0035 0.9000\n",
      "  820 1.0073 0.8850\n",
      "  830 1.0035 0.9025\n",
      "  840 1.0092 0.8875\n",
      "  850 0.9999 0.9075\n",
      "  860 1.0033 0.8975\n",
      "  870 0.9990 0.9050\n",
      "  880 1.0090 0.8850\n",
      "  890 1.0142 0.8700\n",
      "  900 1.0119 0.8875\n",
      "  910 0.9957 0.9175\n",
      "  920 1.0131 0.8900\n",
      "  930 1.0058 0.8975\n",
      "  940 1.0031 0.8925\n",
      "  950 1.0018 0.8950\n",
      "  960 1.0009 0.8950\n",
      "  970 1.0004 0.9075\n",
      "  980 1.0202 0.8775\n",
      "  990 1.0010 0.9050\n",
      " 1000 0.9980 0.9100\n"
     ]
    }
   ],
   "source": [
    "loss_per_ep = []\n",
    "acc_per_ep = []\n",
    "for episode_i, batch in enumerate(dataloader):\n",
    "    train_inputs, train_targets = batch[\"train\"]\n",
    "    seq = inputs_targets_to_seq(train_inputs, train_targets)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    state = model.get_initial_state(batch_size)\n",
    "    y_out = torch.zeros((len(seq), 16, 5))\n",
    "    for j, vector in enumerate(seq):\n",
    "        y_out[j], state = model(vector, state)\n",
    "    loss = F.cross_entropy(y_out.permute(1, 2, 0), train_targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    correct = torch.sum(y_out.permute(1, 2, 0).argmax(dim=1) == train_targets)\n",
    "    acc = correct.item() / np.prod(train_targets.size())\n",
    "\n",
    "    loss_per_ep.append(loss.item())\n",
    "    acc_per_ep.append(acc)\n",
    "\n",
    "    if episode_i % 10 == 0:\n",
    "        print(f\"{episode_i:5d} {loss.item():.4f} {acc:.4f}\")\n",
    "\n",
    "    if episode_i >= 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67d8aadf-0912-41f9-a9e2-8078185ee2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seungjaeryanlee/anaconda3/envs/meta-learning-book/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/seungjaeryanlee/anaconda3/envs/meta-learning-book/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/seungjaeryanlee/anaconda3/envs/meta-learning-book/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/seungjaeryanlee/anaconda3/envs/meta-learning-book/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1403/1413676678.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(self.fc(fc_input)), state\n"
     ]
    }
   ],
   "source": [
    "test_acc_per_ep = []\n",
    "for episode_i, batch in enumerate(dataloader):\n",
    "    test_inputs, test_targets = batch[\"test\"]\n",
    "    seq = inputs_targets_to_seq(test_inputs, test_targets)\n",
    "\n",
    "    state = model.get_initial_state(batch_size)\n",
    "    y_out = torch.zeros((len(seq), 16, 5))\n",
    "    for j, vector in enumerate(seq):\n",
    "        y_out[j], state = model(vector, state)\n",
    "    correct = torch.sum(y_out.permute(1, 2, 0).argmax(dim=1) == test_targets)\n",
    "    acc = correct.item() / np.prod(test_targets.size())\n",
    "\n",
    "    test_acc_per_ep.append(acc)\n",
    "\n",
    "    if episode_i >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "256412d6-bc13-4fc4-bad9-255900527f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8879545454545453"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_acc_per_ep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:meta-learning-book]",
   "language": "python",
   "name": "conda-env-meta-learning-book-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
